providers:
  # Note: "name" is what this connection will show up as in the UI

  - name: "[LOCAL] llama.cpp"
    base_url: http://localhost:8080/v1
    api_key: none

  - name: "[LOCAL] LM Studio"
    base_url: http://localhost:1234/v1
    api_key: none

  - name: "[LOCAL] Ollama"
    base_url: http://localhost:11434/v1
    api_key: none

# Example of using a remote endpoint
# If prefixed with "os.environ/" (similar to LiteLLM), base_url and/or api_key
# will take their value from the named environment variable.

#  - name: "OpenRouter"
#    base_url: https://openrouter.ai/api/v1
#    api_key: os.environ/OPENROUTER_API_KEY
